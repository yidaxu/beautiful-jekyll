---
layout: post
title: NLP
bigimg: /img/path.jpg
tags: [nlp,deep learning]
---
###
morphology: 形态学 


## 如何计算一个句子出现的概率
对于任何一个句子，其出现的概率服从于第一个词出现的概率，第二个词在第一个词出现后出现的概率，最后一个词在前面所有词都出现后在出现的概率
<table width="100%">
<tr>
<td><img src="/img/prob.png" alt="None" ></td>
</tr>
<tr>
  
<table width="100%">
<td>第一个词出现的概率 </td>
<td></td>
  <td></td>
    <td></td>
</tr>
<td><第一个词已经出现 ></td>
<td>第二词出现的概率</td>
  <td></td>
    <td></td>
</tr>
<td><第一个词已经出现 ></td>
<td>第二词已经出现</td>
  <td>第三个词出现的概率</td>
    <td></td>
</tr>
<td><第一个词已经出现 ></td>
<td>第二词已经出现</td>
  <td>倒数第二个词出现</td>
    <td>最后一个词出现的概率</td>
</tr>

问题是，如何计算这个条件概率
## Count based language Models
### Count-based Language Models
<table width="100%">
<tr>
<td><img src="/img/cbl.png" alt="None" ></td>
</tr>
<tr>
 
整体思如如下
<table width="100%">
<tr>
<td> I love (100)</td>
<td> I love you(10)</td>
 <td> P(you|I love) = 10 /100 </td>
</tr>
<tr>
<td> 缺点：有可能 I love you 在数据库中一次也没出现</td>
<td> 解决方法：add-smooth</td>
</tr>
  
### 评价标准
* 基本上的核心就是对数据库里的每一个句子，求其出现的概率，最后再求和。
### 有了模型，我们能做什么
* 评价句子：看句子出现的概率有多大。 符合人类语言习惯的句子，出现的概率大，不符合的出现的概率小。
* 产生句子
```python
while didn't choose end of sentence symbol:
  计算条件概率
  根据条件概率抽样
```
## Featurized Models
* 基于Feature 来计算概率
* 通过优化算法来优化Feature weight 来获取最优解

### 最常见的优化函数叫做 negative log likelihood
p = [........]， p分布在整个样本空间的一组加权为1的概率集合
第i个元素为correct answer
-log(p(i)) 就是这个样本的negative log likelihood

### UNK
